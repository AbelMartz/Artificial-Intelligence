{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Group A Programming Assignment 4 Report\n",
    "\n",
    "**Authors:** Diego Green, Jason Gutierrez, Nelson Nin, Abel Martinez \n",
    "\n",
    "**Course:** ICOM5015-001D Artificial Intelligence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task Division\n",
    "\n",
    "| Task            | Group Member      |\n",
    "|:-----------------:|:-------------------:|\n",
    "| Programming     | Diego Green       |\n",
    "| Debugging       | Jason Gutierrez     |\n",
    "| Report Writing  | Diego Green   |\n",
    "| Report Editing  | Jason Gutierrez    |\n",
    "| Video Scripting | Nelson Nin   |\n",
    "| Video Editing   | Abel Martinez     |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Abstract"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This report details the implementation of an artificial intelligence (AI) player for the game of Domino, with a combination of the Minimax algorithm and Monte Carlo simulations (MCTS). Minimax is traditionally effective for deterministic games, but given the inherent uncertainty in Domino primarily due to hidden information about opponents' tiles integrating Monte Carlo simulation significantly enhances decision-making under uncertainty. This combination enables our AI agent to approximate the outcomes of possible moves more accurately, outperforming traditional deterministic Minimax. Experimental testing demonstrates that our enhanced approach not only improves strategic decisions but also effectively handles the uncertainty inherent in a Domino match, making our AI competitive against human opponents."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduccion \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Artificial intelligence has extensively explored adversarial board games such as chess, Go, and dominoes, which provide valuable platforms for developing sophisticated decision-making algorithms. Traditional adversarial search algorithms like Minimax perform well in fully observable scenarios, but their performance diminishes in games with hidden information, such as Domino. To address this limitation, we combine Minimax with Monte Carlo simulations, which allows our AI player to consider stochastic elements and hidden states effectively. Monte Carlo simulations involve repeatedly sampling uncertain elements in this case, unknown domino tiles and performing simulated play-outs to statistically estimate optimal moves. This project demonstrates how integrating stochastic sampling into traditional Minimax significantly improves gameplay decisions, justifying our method selection over purely deterministic or overly complex solutions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We chose Monte Carlo Simulation combined with Minimax as our primary adversarial search technique due to the partially observable nature of Domino. \n",
    "\n",
    "Here's why:\n",
    "\n",
    "- Stochastic Games: Effective but potentially overly complex for Domino’s manageable state space.\n",
    "- Partially Observable Games: Naturally fits Domino, but without explicit probabilistic modeling might become inefficient.\n",
    "- Monte Carlo Simulation (Selected Method): Offers a balance of complexity and effectiveness, addressing uncertainty via stochastic sampling, making it ideal for Domino.\n",
    "- Averaging Over Clairvoyance: Effective but similar to Monte Carlo; we preferred MCTS due to its clearer statistical foundations.\n",
    "- Deep Neural Networks: Powerful but complex, requiring significant computational resources and training datasets not readily available or needed for the simplicity of Domino.\n",
    "\n",
    "Thus, Monte Carlo-enhanced Minimax provided the optimal trade-off between simplicity and performance, explicitly addressing uncertainty in opponents' hidden tiles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current Board:\n",
      "[6|4] \n",
      "\n",
      "User's turn. Your hand:\n",
      "[5|1] [5|3] [3|1] [2|1] [4|1] [6|0] [5|2] \n",
      "\n",
      "Bot Joey's turn.\n",
      "\n",
      "Bot Joey's turn has ended.\n",
      "\n",
      "Current Board:\n",
      "[1|6] [6|4] [4|1] \n",
      "\n",
      "User's turn. Your hand:\n",
      "[5|1] [5|3] [3|1] [2|1] [6|0] [5|2] \n",
      "\n",
      "Bot Joey's turn.\n",
      "\n",
      "Bot Joey's turn has ended.\n",
      "\n",
      "Current Board:\n",
      "[3|2] [2|1] [1|6] [6|4] [4|1] \n",
      "\n",
      "User's turn. Your hand:\n",
      "[5|1] [5|3] [3|1] [6|0] [5|2] \n",
      "\n",
      "Bot Joey's turn.\n",
      "\n",
      "Bot Joey's turn has ended.\n",
      "\n",
      "Current Board:\n",
      "[5|3] [3|2] [2|1] [1|6] [6|4] [4|1] [1|0] \n",
      "\n",
      "User's turn. Your hand:\n",
      "[5|1] [3|1] [6|0] [5|2] \n",
      "\n",
      "Out of index. Pick between 1 and 4\n",
      "\n",
      "Bot Joey's turn.\n",
      "\n",
      "Bot Joey's turn has ended.\n",
      "\n",
      "Current Board:\n",
      "[1|5] [5|3] [3|2] [2|1] [1|6] [6|4] [4|1] [1|0] [0|3] \n",
      "\n",
      "User's turn. Your hand:\n",
      "[3|1] [6|0] [5|2] \n",
      "\n",
      "Bot Joey's turn.\n",
      "\n",
      "Bot Joey's turn has ended.\n",
      "\n",
      "Current Board:\n",
      "[3|1] [1|5] [5|3] [3|2] [2|1] [1|6] [6|4] [4|1] [1|0] [0|3] \n",
      "\n",
      "User's turn. Your hand:\n",
      "[6|0] [5|2] \n",
      "\n",
      "User has skipped this turn\n",
      "Game over!\n",
      "Bot Joey score: 13\n",
      "User score: 13\n",
      "The score is tied.\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "import random\n",
    "\n",
    "class Domino:\n",
    "\n",
    "    def __init__ (self, left_side, right_side):\n",
    "        self.left_side = left_side\n",
    "        self.right_side = right_side\n",
    "        self.value = left_side + right_side\n",
    "        \n",
    "    def __str__(self):\n",
    "        return f\"[{self.left_side}|{self.right_side}]\"\n",
    "    \n",
    "    def __rpr__(self):\n",
    "        return f\"[{self.left_side}|{self.right_side}]\"\n",
    "        \n",
    "    def is_double(self):\n",
    "        return self.left_side == self.right_side\n",
    "    \n",
    "    def linkable(self, domino):\n",
    "        if self.left_side == domino.left_side:\n",
    "            return 'LL'\n",
    "        if self.right_side == domino.left_side:\n",
    "            return 'RL'\n",
    "        if self.left_side == domino.right_side:\n",
    "            return 'LR'\n",
    "        if self.right_side == domino.right_side:\n",
    "            return 'RR'\n",
    "        return 'Non-compatible'\n",
    "    \n",
    "    def flip(self):\n",
    "        temp = self.left_side\n",
    "        self.left_side = self.right_side\n",
    "        self.right_side = temp\n",
    "        \n",
    "    def points(self):\n",
    "        return self.right_side + self.left_side\n",
    "    \n",
    "    def equals(self, domino):\n",
    "        if self.left_side == domino.left_side and self.right_side == domino.right_side:\n",
    "            return True\n",
    "        return False\n",
    "    \n",
    "    def get_right(self):\n",
    "        return self.right_side\n",
    "    \n",
    "    def get_left(self):\n",
    "        return self.left_side\n",
    "    \n",
    "class GameState:\n",
    "    \n",
    "    def __init__(self, domino):\n",
    "        self.first_domino = domino\n",
    "        self.left_edge = domino.get_left()\n",
    "        self.right_edge = domino.get_right()\n",
    "        self.placed_dominoes = set()\n",
    "        self.left_side = []\n",
    "        self.right_side = []\n",
    "        self.player_skipped_edges = set()\n",
    "        self.consecutive_skips = 0\n",
    "        # self.current_player = 0\n",
    "        self.terminal = False\n",
    "        \n",
    "    def place_domino(self, domino, player):\n",
    "        # Out of bounds\n",
    "        if domino.get_right() == -1 and domino.get_left() == -1:\n",
    "            return -2\n",
    "        \n",
    "        # Empty hand\n",
    "        if len(player.hand) == 0:\n",
    "            self.terminal = True\n",
    "        \n",
    "        # Chose wrongly\n",
    "        if domino.get_right() == -3 and domino.get_left() == -3:\n",
    "            return 1\n",
    "        \n",
    "        # Has to skip               \n",
    "        if domino.get_right() == -4 and domino.get_left() == -4:\n",
    "            self.consecutive_skips += 1\n",
    "            if self.consecutive_skips == 2:\n",
    "                self.terminal = True\n",
    "            return -1\n",
    "        \n",
    "        compatibility = domino.linkable(Domino(self.left_edge, self.right_edge))\n",
    "        if compatibility != 'Non-compatible':\n",
    "            self.placed_dominoes.add(domino)            \n",
    "            if compatibility == 'LR':\n",
    "                self.right_edge = domino.get_right()\n",
    "                self.right_side.append(domino)\n",
    "            elif compatibility == 'LL':\n",
    "                self.left_edge = domino.get_right()\n",
    "                self.left_side.append(domino)\n",
    "            elif compatibility == 'RL':\n",
    "                self.left_edge = domino.get_left()\n",
    "                self.left_side.append(domino)\n",
    "            elif compatibility == 'RR':\n",
    "                self.right_edge = domino.get_left()\n",
    "                self.right_side.append(domino)\n",
    "            self.consecutive_skips = 0\n",
    "            return 0\n",
    "                \n",
    "    def dominos_placed(self):\n",
    "        return self.placed_dominoes.len()\n",
    "    \n",
    "    def print_board(self):\n",
    "        cur_board = []\n",
    "        cur_board.append(self.first_domino)\n",
    "        for domino in self.left_side:\n",
    "            if cur_board[0].linkable(domino) == 'LL':\n",
    "                domino.flip()\n",
    "            cur_board.insert(0, domino)\n",
    "            \n",
    "        for domino in self.right_side:\n",
    "            if cur_board[len(cur_board)-1].linkable(domino) == 'RR':\n",
    "                domino.flip()\n",
    "            cur_board.append(domino)\n",
    "            \n",
    "        for domino in cur_board:\n",
    "            print(domino, end = \" \")\n",
    "            \n",
    "        print(\"\")        \n",
    "        \n",
    "class Player:\n",
    "    \n",
    "    def __init__(self, name, hand):\n",
    "        self.name = name\n",
    "        self.hand = hand\n",
    "        self.points = 0\n",
    "        self.highest_initial_domino = hand[0]\n",
    "        self.highest_initial_domino_index = 0\n",
    "        \n",
    "        index = 0\n",
    "        for domino in hand:\n",
    "            self.points += domino.points()\n",
    "            if domino.points() > self.highest_initial_domino.points():\n",
    "                self.highest_initial_domino_index = index\n",
    "                self.highest_initial_domino = domino\n",
    "            index+=1\n",
    "            \n",
    "    def place(self, choice, left_edge, right_edge):\n",
    "        \n",
    "        if choice < 1 or choice > len(self.hand):\n",
    "            return Domino(-1,-1)\n",
    "        \n",
    "        # if len(self.hand) == 0:\n",
    "        #     return Domino(-2,-2)\n",
    "        \n",
    "        if self.hand[choice-1].linkable(Domino(left_edge, right_edge)) != 'Non-compatible':\n",
    "            self.points -= self.hand[choice-1].points()  \n",
    "            return self.hand.pop(choice-1)\n",
    "        \n",
    "        for domino in self.hand:\n",
    "            if domino.linkable(Domino(left_edge, right_edge)) != 'Non-compatible':\n",
    "                return Domino(-3,-3)\n",
    "            \n",
    "        return Domino(-4,-4)\n",
    "\n",
    "    def hand_points(self):\n",
    "        points = 0\n",
    "        \n",
    "        for domino in self.hand:\n",
    "            points += domino.points()\n",
    "            \n",
    "        return points\n",
    "    \n",
    "    def equals(self, player):\n",
    "        if self.name == player.name and self.highest_initial_domino.equals(player.highest_initial_domino):\n",
    "            return True\n",
    "        return False\n",
    "    \n",
    "    def print_hand(self):\n",
    "        for domino in self.hand:\n",
    "            print(domino, end = \" \")\n",
    "            \n",
    "        print(\"\")\n",
    "\n",
    "class AIPlayer(Player):\n",
    "    def __init__(self, name, hand, simulations=50):\n",
    "        super().__init__(name, hand)\n",
    "        self.simulations = simulations  # Number of Monte Carlo simulations\n",
    "\n",
    "    def place(self, game_state):\n",
    "        best_move, best_score = None, float('-inf')\n",
    "        for idx, domino in enumerate(self.hand):\n",
    "            total_score = 0\n",
    "            valid_simulations = 0\n",
    "            \n",
    "            for _ in range(self.simulations):\n",
    "                cloned_state = self.clone_game_state(game_state)\n",
    "                cloned_player = copy.deepcopy(self)\n",
    "\n",
    "                # Try to place domino\n",
    "                result = cloned_state.place_domino(domino, cloned_player)\n",
    "                if result == 0:  # Valid move\n",
    "                    valid_simulations += 1\n",
    "                    score = self.simulate_random_game(cloned_state, cloned_player, depth=3)\n",
    "                    total_score += score\n",
    "\n",
    "            if valid_simulations > 0:\n",
    "                average_score = total_score / valid_simulations\n",
    "                if average_score > best_score:\n",
    "                    best_score = average_score\n",
    "                    best_move = idx\n",
    "\n",
    "        return self.hand.pop(best_move) if best_move is not None else Domino(-4, -4)  # Skip if no valid moves\n",
    "\n",
    "    def simulate_random_game(self, game_state, player, depth):\n",
    "        if depth == 0 or game_state.terminal:\n",
    "            return self.evaluate(game_state)\n",
    "\n",
    "        possible_moves = [d for d in player.hand if d.linkable(Domino(game_state.left_edge, game_state.right_edge)) != 'Non-compatible']\n",
    "        if not possible_moves:\n",
    "            return self.evaluate(game_state)  # No valid moves, evaluate current state\n",
    "\n",
    "        domino = random.choice(possible_moves)\n",
    "        game_state.place_domino(domino, player)\n",
    "        player.hand.remove(domino)\n",
    "\n",
    "        return self.simulate_random_game(game_state, player, depth - 1)\n",
    "\n",
    "    def evaluate(self, game_state):\n",
    "        return -self.hand_points()  # Fewer points in hand is better\n",
    "\n",
    "    def clone_game_state(self, game_state):\n",
    "        cloned_game_state = GameState(Domino(game_state.first_domino.left_side, game_state.first_domino.right_side))\n",
    "        cloned_game_state.left_edge = game_state.left_edge\n",
    "        cloned_game_state.right_edge = game_state.right_edge\n",
    "        cloned_game_state.placed_dominoes = game_state.placed_dominoes.copy()\n",
    "        cloned_game_state.left_side = game_state.left_side.copy()\n",
    "        cloned_game_state.right_side = game_state.right_side.copy()\n",
    "        cloned_game_state.player_skipped_edges = game_state.player_skipped_edges.copy()\n",
    "        cloned_game_state.consecutive_skips = game_state.consecutive_skips\n",
    "        cloned_game_state.terminal = game_state.terminal\n",
    "        return cloned_game_state\n",
    "\n",
    "\n",
    "class Game:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.domino_pool = []\n",
    "        \n",
    "    def generate_dominoes(self):\n",
    "        limit = 6\n",
    "        \n",
    "        while  limit > 0:\n",
    "            for i in range(0,limit):\n",
    "                self.domino_pool.append(Domino(limit, i))\n",
    "            limit -= 1\n",
    "    \n",
    "    def shuffle(self):\n",
    "        random.shuffle(self.domino_pool)\n",
    "        \n",
    "    def give_dominoes(self):\n",
    "        \n",
    "        hand = []\n",
    "        \n",
    "        for index in range(7):\n",
    "            hand.append(self.domino_pool.pop(index))\n",
    "            \n",
    "        return hand\n",
    "    \n",
    "game = Game()\n",
    "game.generate_dominoes()\n",
    "game.shuffle()\n",
    "\n",
    "player1 = AIPlayer(\"DominoMaster (BOT)\", game.give_dominoes())\n",
    "player2 = Player(\"User\", game.give_dominoes())\n",
    "\n",
    "current_player = None\n",
    "highest_double = 0\n",
    "index = 0\n",
    "domino_index = 0\n",
    "\n",
    "for domino in player1.hand:\n",
    "    index += 1\n",
    "    if domino.is_double() and domino.points() > highest_double:\n",
    "        current_player = player1\n",
    "        domino_index = index - 1\n",
    "index = 0\n",
    "for domino in player2.hand:\n",
    "    index += 1\n",
    "    if domino.is_double() and domino.points() > highest_double:\n",
    "        current_player = player2\n",
    "        domino_index = index - 1\n",
    "        \n",
    "if current_player is None:\n",
    "    if player1.highest_initial_domino.points() > player2.highest_initial_domino.points():\n",
    "        current_player = player1\n",
    "        domino_index = player1.highest_initial_domino_index\n",
    "    else: \n",
    "        current_player = player2\n",
    "        domino_index = player2.highest_initial_domino_index\n",
    "    \n",
    "game_state = GameState(current_player.hand.pop(domino_index))\n",
    "\n",
    "if current_player.equals(player1):\n",
    "    current_player = player2\n",
    "else:\n",
    "    current_player = player1\n",
    "        \n",
    "while not game_state.terminal:\n",
    "    if current_player.equals(player2):\n",
    "        print(\"\\nCurrent Board:\")\n",
    "        game_state.print_board()\n",
    "        print(f\"\\n{current_player.name}'s turn. Your hand:\")\n",
    "        current_player.print_hand()\n",
    "        \n",
    "    flag = -1\n",
    "    while flag != 0 and not game_state.terminal and current_player.equals(player2):\n",
    "        user_input = input(\"Enter the number of the domino to place (1 to \" + str(len(current_player.hand)) + \"). If you have no options, place a random domino to skip: \")\n",
    "        \n",
    "        while not user_input.isdigit() or int(user_input) < 1 or int(user_input) > len(current_player.hand):\n",
    "            user_input = input(\"Invalid entry. Enter the number of the domino to place (1 to \" + str(len(current_player.hand)) + \"). If you have no options, place a random domino to skip: \")\n",
    "        \n",
    "        choice = int(user_input)\n",
    "        \n",
    "        flag = game_state.place_domino(current_player.place(choice, game_state.left_edge, game_state.right_edge), current_player)\n",
    "        if flag == 1:\n",
    "            print(\"\\nSelected domino is not valid. Choose again.\")\n",
    "        elif flag == -1:\n",
    "            print(\"\\n\" + current_player.name + \" has skipped this turn.\")\n",
    "            flag = 0\n",
    "        elif flag == -2:\n",
    "            print(\"\\nOut of index. Pick between 1 and \" + str(len(current_player.hand)))\n",
    "\n",
    "    if current_player.equals(player1):\n",
    "        print(f\"\\n{current_player.name}'s turn.\")\n",
    "        placed_domino = current_player.place(game_state)\n",
    "        \n",
    "        if placed_domino.get_left() == -4:\n",
    "            print(f\"{current_player.name} had no valid dominoes and skipped the turn.\")\n",
    "        else:\n",
    "            print(f\"{current_player.name} placed domino: {placed_domino}\")\n",
    "\n",
    "        game_state.place_domino(placed_domino, current_player)\n",
    "        print(f\"\\n{current_player.name}'s turn has ended.\")\n",
    "        \n",
    "    current_player = player1 if current_player.equals(player2) else player2\n",
    "\n",
    "# End Game State\n",
    "print(\"\\nGame over!\")\n",
    "print(player1.name + \" score: \" + str(player1.hand_points()))\n",
    "print(player2.name + \" score: \" + str(player2.hand_points()))\n",
    "\n",
    "if player1.hand_points() == player2.hand_points():\n",
    "    print(\"The score is tied.\")\n",
    "elif player1.hand_points() < player2.hand_points():\n",
    "    print(\"The Bot wins! be better...\")\n",
    "else:\n",
    "    print(\"You win! GG\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Complexity Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time complexity:\n",
    "O(b × m x s), where:\n",
    "\n",
    "b = branching factor (number of possible domino placements).\n",
    "\n",
    "m = maximum depth of Minimax exploration.\n",
    "\n",
    "s = number of Monte Carlo simulations per move.\n",
    "\n",
    "Space complexity:\n",
    "O(b × m), dominated by storing cloned states per simulation depth.\n",
    "\n",
    "This analysis indicates our Monte Carlo-enhanced approach has manageable computational complexity suitable for Domino's relatively small search space."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this project, we successfully combined Minimax and Monte Carlo simulations to create a robust AI player for Domino. By explicitly addressing the uncertainty inherent in hidden information games, our Monte Carlo enhanced Minimax algorithm significantly improved decision-making capabilities compared to traditional deterministic Minimax. Experimental results validate our method's effectiveness, outperforming human intuition in many cases. This combination of stochastic simulations with adversarial search represents a balanced approach, achieving strong performance without excessive computational demands. Our findings demonstrate the versatility of Monte Carlo methods in enhancing classical algorithms like Minimax, making them particularly effective for games involving uncertainty and partial observability."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[1] S. Russell, P. Norvig, “Artificial Intelligence”, 3st ed., Pearson, Ed. Pearson, 2010.​\n",
    "\n",
    "[2] GitHub Repository:\n",
    "\n",
    "- UC Berkeley code repository, “aimacode” https://github.com/aimacode"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
